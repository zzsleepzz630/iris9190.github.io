---
layout: post
title:  "중간고사 이전까지 배운내용 정리"
date:   2018-10-01 10:01:13
categories: Data_science
permalink: /archivers/python_lecture_01
---

# 그동안 배운내용 정리.md


1장

빅데이터: 기존의 방식으로 저장/관리/분석하기 어려울 정도로 큰 규모의 자료 의미
- 기존?- 특정용량의미x데이터에 결합된 정보의 복잡성과 분석과정에서 요구되는 속도도 기존의 의미와 구별.
-규모에 초점을 맞춘 정의(McKinsey): 일반적인 데이터 베이그 sw가 저장 관리 분석할 수 있는 범위를 초과하는 규모의 데이터.
-업무수행에 초점을 맞춘 정의(IDC): 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고 데이터의 초고속 수집 발굴 분석을 지원하도록 고안된 차세대 기술 밑 아키텍쳐

Variety (다양성)
기존 기업 내부 데이터 축적 뿐만 아니라 외부 데이터의 폭증과 함께 IoT서비스에서 나오는 데이터까지 다양해짐. 최근 ‘생활 데이터’라고 불리며 개인이 생산해내는 데이터의 양과 종류가 증가하여 주목. 기존에 분석하기 어려웠던 비정형 데이터의 분석기법까지 등장하면서 분석할 수 있는 데이터의 종류도 다양해짐

기술 특이점: 빅데이터를 다룰 수 있는 시스템이 오픈소스로 공개되고 gpgpu기술이 도입되어 연산속도가 비약적으로 향상.  

Gpgpu
 일반적으로 컴퓨터 그래픽스를 위한 계산만 맡았던 그래픽 처리 장치(GPU)를, 전통적으로 중앙 처리 장치(CPU)가 맡았던 응용 프로그램들의 계산에 사용하는 기술이다

Volume
GFS(Google file system) 
-여러대의 저사양 pc를 하나의 슈퍼컴처럼 사용하는 분산컴퓨팅 기술의 근간
-이후 야후와 아파치 재단이 이를 참조하여 만들어 오픈소스화 한건이 Hadoop Distributed File System이다. 이는 일반 사기업도 상용목적으로 이용가능하여 빅데이터 분석 보급에 기여하였다. 
-도입 이후 분석 시간이 3일-3시간으로 단축되었고 데이터 활용 규모도 2tb에서 15tb로 증가하였다.

스파크
-기존 HDFS에서 발생한 I/O 속도 저하를 Imutable in Memory를 활용하여 획기적인 속도 향상을 구현.
-데이터의 append가 가능한 HDFS과 달리 read only이기 때문에 In Memory HDFS에 비해서도 뛰어난 성능. RAM을 ROM처럼 활용
-HDFS에 비해 시스템 구성이 간결, 인터페이스가 뛰어나 리소스 도입비용 측명에서 강점. 

CAP이론 : 
Consistency 일관성: 모든 사용자는 항상 동시에 같은 데이터를 조회한다. 
Availability 가용성: 모든 사용자는 항상 read/write 할 수 있으며 몇몇 노드 장애시에도 다른 노드들의 작동을 보장한다. 
Partition Tolerance 파티션 내용성: 물리적으로 분산된 네트워크상에서 메시지 손실로 인한 부분적 결함이 있어도 자동복구되어 정상적으로 동작한다. 

Velocity
암 진단을 위한 분석 시스템의 필요에 의해 gpgpu개념 처음으로 등장. 그래픽 연산에만 사용되었던 gpu를 Nvidia에서 General Purpose GPU로 활용 가능한 기술로 오픈소스화
⎫	특정 단순 반복 연산이 많이 이루어지는 Task에 있어 고성능을 발휘.
⎫	성능 향상에 비해 투자가격이 매우 저렴한 편 

알파고
GPGPU 기술은 실시간으로 변화하는 조건에 맞는 최적의 수를 추천하는데 활용됨
⎫	알파고는 Value Network(승률)와 Policy network(기보)를 사용하면서 강화학습 기반의 Monte Carlo tree search 알고리즘을 활용*
⎫	40 search threads, 1,202 CPUs and 176GPUs 사용*
⎫	CPU는 각 노드를 Control 하고 GPU의 연산 결과를 활용하는데에 주로 사용 
틱택톡빙고게임도 같이함.

독점기업의 이윤 모델
⎫	빅데이터 비즈니스 모델의 경쟁력은 차별화된 특징, 독점성, 저비용 3가지 측면에 있음. 
⎫	즉, 저렴한 비용으로 자신만이 보유한 데이터를 차별화된 방법으로 분석하여 경쟁력을 확보하는 것.
⎫	디지털 고객 가치 추구에 빅데이터가 가진 경쟁력을 활용한다면 새로운 비즈니스 기회를 모색할 수 있음. 
⎫	
4장

깃
Git은 분산 저장식 버전관리 시스템
SVN은 중앙집중식 버전관리 시스템
SVN네트워크 연결x-사용x
GIT o
⎫	논리적 단위의 차이 SVN은 Snapshot, Git은 Commit
⎫	Git은 변경되지 않은 파일에 대해서는 파일 자체가 아니라 link를 활용함

버전관리
버전 관리 시스템은 파일 변화를 시간에 따라 기록했다가 나중에 특정 시점의 버전을 다시 꺼내올 수 있는 시스템이다.
⎫	SW 형상 관리 (Software Configuration Management)의 일환으로 소스 코드 관리(Source Code Management)는 개발에 있어 필수적임
⎫	중앙집중형과 분산형이 있음

깃플로우
일반적으로 SW를 유지보수 함에 있어서, 아래와 같은 Git Flow 구조를 사용하는 경우가 많음. 
마스터-핫픽스-릴리스-디벨롭-피쳐
큰 에러발견시 급 수정: 핫픽스 브랜치
디벨롭: 분석을 점차 적용해 나가는브랜치

깃연동(Pull Request 의 단계)
1.	Fork 원작자의 저장소를 복제
2.	Clone 원격조장소를 로컬 저장소로 다운로드
3.	Branch 마스터 브랜치에서 디벨롭 또는 다른 작업을 할 브랜지를 생성
4.	Checkout 작업할 브랜치로 변경
5.	Souce Change 수정이 필요한 부분의소스를 변경
6.	Commit 변경한 소스를 로컬 저장소에저장 ㄴㄱ
7.	Push 로컬 저장소의 작업 브랜치를 원경 저장소로 업로드
8.	Pull Request 변경 사항을 원작자에게 원본 소스에 반영 요청 송신





5장

데이터 분석 프로세스
Server에서 누적된 데이터와 실시간으로 발생되는 데이터를 병합하여 처리 
⎫	Python을 통해 데이터를 수집하고, String 연산, 정규표현식 등을 활용하여 csv 파일로 정제
⎫	일반 Desktop에서 다루기 어려운 규모의 Data는 Linux Server를 통해서 Data Handling
⎫	Python의 ggplot, Tableau 등으로 데이터 시각화
⎫	데이터분석이 한번 돌아서 끝나는게 아니라 그때그때 이전단계로 돌아갈 수 있고 단계별로 피드백 가능

Confusion Matrix

용어정리
precision = 
정밀도. = Positive predictive value 양성예측도. 예측한 p중 맞춘 p
P = TP/(TP+FP)
recall =
재현율=민감도 sensitivity. 실제 p중 맞춘 p
R = TP/(TP+FN)
F-measure
2*P*R/(P+R)
Negative 
predictive value
음성예측도. 예측한 n중 맞춘 n
NPV = TN / (FN+TN)
specificity
특이도. 실제n중 맞춘 n
S = TN / (FP+FN) 
error rate
오분류율. 모든 경우의 수 중에 틀린 것
E = (FP+FN) / ALL
ALL = TP+FP+TN+FN
accuracy rate = 
정분류율 = 정확도. 모든 경우의 수 중에 맞은 것
A = (TP+TN) / ALL
type I error
p라고 예측했는데 실제는 n인 것. 
예측이 잘못된 것.
type II error
n이라고 예측했는데 실제는 p인 것. 
예측했어야 하는 것.  더 심각


K fold Test
Training / Test set / Validation set 을 나누어, 훈련, 테스트, 검증의 과정을 K회 진행하여 성능을 도출[1]
⎫	Sample 분화: Training Set 모델 만들 때 사용 / Validating Set 모델 조정하기 위해 사용 Test Set 모델의 최종 평가 위해 사용[2]
⎫	충분한 교차검증을 거치지 않을경우, 훈련 데이터에만 최적화 되는 과적합Overfitting이 일어남 . 오버피팅:  편향적으로 학습이 된 것.
1장

빅데이터: 기존의 방식으로 저장/관리/분석하기 어려울 정도로 큰 규모의 자료 의미
- 기존?- 특정용량의미x데이터에 결합된 정보의 복잡성과 분석과정에서 요구되는 속도도 기존의 의미와 구별.
-규모에 초점을 맞춘 정의(McKinsey): 일반적인 데이터 베이그 sw가 저장 관리 분석할 수 있는 범위를 초과하는 규모의 데이터.
-업무수행에 초점을 맞춘 정의(IDC): 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고 데이터의 초고속 수집 발굴 분석을 지원하도록 고안된 차세대 기술 밑 아키텍쳐

Variety (다양성)
기존 기업 내부 데이터 축적 뿐만 아니라 외부 데이터의 폭증과 함께 IoT서비스에서 나오는 데이터까지 다양해짐. 최근 ‘생활 데이터’라고 불리며 개인이 생산해내는 데이터의 양과 종류가 증가하여 주목. 기존에 분석하기 어려웠던 비정형 데이터의 분석기법까지 등장하면서 분석할 수 있는 데이터의 종류도 다양해짐

기술 특이점: 빅데이터를 다룰 수 있는 시스템이 오픈소스로 공개되고 gpgpu기술이 도입되어 연산속도가 비약적으로 향상.  

Gpgpu
 일반적으로 컴퓨터 그래픽스를 위한 계산만 맡았던 그래픽 처리 장치(GPU)를, 전통적으로 중앙 처리 장치(CPU)가 맡았던 응용 프로그램들의 계산에 사용하는 기술이다

Volume
GFS(Google file system) 
-여러대의 저사양 pc를 하나의 슈퍼컴처럼 사용하는 분산컴퓨팅 기술의 근간
-이후 야후와 아파치 재단이 이를 참조하여 만들어 오픈소스화 한건이 Hadoop Distributed File System이다. 이는 일반 사기업도 상용목적으로 이용가능하여 빅데이터 분석 보급에 기여하였다. 
-도입 이후 분석 시간이 3일-3시간으로 단축되었고 데이터 활용 규모도 2tb에서 15tb로 증가하였다.

스파크
-기존 HDFS에서 발생한 I/O 속도 저하를 Imutable in Memory를 활용하여 획기적인 속도 향상을 구현.
-데이터의 append가 가능한 HDFS과 달리 read only이기 때문에 In Memory HDFS에 비해서도 뛰어난 성능. RAM을 ROM처럼 활용
-HDFS에 비해 시스템 구성이 간결, 인터페이스가 뛰어나 리소스 도입비용 측명에서 강점. 

CAP이론 : 
Consistency 일관성: 모든 사용자는 항상 동시에 같은 데이터를 조회한다. 
Availability 가용성: 모든 사용자는 항상 read/write 할 수 있으며 몇몇 노드 장애시에도 다른 노드들의 작동을 보장한다. 
Partition Tolerance 파티션 내용성: 물리적으로 분산된 네트워크상에서 메시지 손실로 인한 부분적 결함이 있어도 자동복구되어 정상적으로 동작한다. 

Velocity
암 진단을 위한 분석 시스템의 필요에 의해 gpgpu개념 처음으로 등장. 그래픽 연산에만 사용되었던 gpu를 Nvidia에서 General Purpose GPU로 활용 가능한 기술로 오픈소스화
⎫	특정 단순 반복 연산이 많이 이루어지는 Task에 있어 고성능을 발휘.
⎫	성능 향상에 비해 투자가격이 매우 저렴한 편 

알파고
GPGPU 기술은 실시간으로 변화하는 조건에 맞는 최적의 수를 추천하는데 활용됨
⎫	알파고는 Value Network(승률)와 Policy network(기보)를 사용하면서 강화학습 기반의 Monte Carlo tree search 알고리즘을 활용*
⎫	40 search threads, 1,202 CPUs and 176GPUs 사용*
⎫	CPU는 각 노드를 Control 하고 GPU의 연산 결과를 활용하는데에 주로 사용 
틱택톡빙고게임도 같이함.

독점기업의 이윤 모델
⎫	빅데이터 비즈니스 모델의 경쟁력은 차별화된 특징, 독점성, 저비용 3가지 측면에 있음. 
⎫	즉, 저렴한 비용으로 자신만이 보유한 데이터를 차별화된 방법으로 분석하여 경쟁력을 확보하는 것.
⎫	디지털 고객 가치 추구에 빅데이터가 가진 경쟁력을 활용한다면 새로운 비즈니스 기회를 모색할 수 있음. 
⎫	
4장

깃
Git은 분산 저장식 버전관리 시스템
SVN은 중앙집중식 버전관리 시스템
SVN네트워크 연결x-사용x
GIT o
⎫	논리적 단위의 차이 SVN은 Snapshot, Git은 Commit
⎫	Git은 변경되지 않은 파일에 대해서는 파일 자체가 아니라 link를 활용함

버전관리
버전 관리 시스템은 파일 변화를 시간에 따라 기록했다가 나중에 특정 시점의 버전을 다시 꺼내올 수 있는 시스템이다.
⎫	SW 형상 관리 (Software Configuration Management)의 일환으로 소스 코드 관리(Source Code Management)는 개발에 있어 필수적임
⎫	중앙집중형과 분산형이 있음

깃플로우
일반적으로 SW를 유지보수 함에 있어서, 아래와 같은 Git Flow 구조를 사용하는 경우가 많음. 
마스터-핫픽스-릴리스-디벨롭-피쳐
큰 에러발견시 급 수정: 핫픽스 브랜치
디벨롭: 분석을 점차 적용해 나가는브랜치

깃연동(Pull Request 의 단계)
1.	Fork 원작자의 저장소를 복제
2.	Clone 원격조장소를 로컬 저장소로 다운로드
3.	Branch 마스터 브랜치에서 디벨롭 또는 다른 작업을 할 브랜지를 생성
4.	Checkout 작업할 브랜치로 변경
5.	Souce Change 수정이 필요한 부분의소스를 변경
6.	Commit 변경한 소스를 로컬 저장소에저장 ㄴㄱ
7.	Push 로컬 저장소의 작업 브랜치를 원경 저장소로 업로드
8.	Pull Request 변경 사항을 원작자에게 원본 소스에 반영 요청 송신





5장

데이터 분석 프로세스
Server에서 누적된 데이터와 실시간으로 발생되는 데이터를 병합하여 처리 
⎫	Python을 통해 데이터를 수집하고, String 연산, 정규표현식 등을 활용하여 csv 파일로 정제
⎫	일반 Desktop에서 다루기 어려운 규모의 Data는 Linux Server를 통해서 Data Handling
⎫	Python의 ggplot, Tableau 등으로 데이터 시각화
⎫	데이터분석이 한번 돌아서 끝나는게 아니라 그때그때 이전단계로 돌아갈 수 있고 단계별로 피드백 가능

Confusion Matrix

용어정리
precision = 
정밀도. = Positive predictive value 양성예측도. 예측한 p중 맞춘 p
P = TP/(TP+FP)
recall =
재현율=민감도 sensitivity. 실제 p중 맞춘 p
R = TP/(TP+FN)
F-measure
2*P*R/(P+R)
Negative 
predictive value
음성예측도. 예측한 n중 맞춘 n
NPV = TN / (FN+TN)
specificity
특이도. 실제n중 맞춘 n
S = TN / (FP+FN) 
error rate
오분류율. 모든 경우의 수 중에 틀린 것
E = (FP+FN) / ALL
ALL = TP+FP+TN+FN
accuracy rate = 
정분류율 = 정확도. 모든 경우의 수 중에 맞은 것
A = (TP+TN) / ALL
type I error
p라고 예측했는데 실제는 n인 것. 
예측이 잘못된 것.
type II error
n이라고 예측했는데 실제는 p인 것. 
예측했어야 하는 것.  더 심각


K fold Test
Training / Test set / Validation set 을 나누어, 훈련, 테스트, 검증의 과정을 K회 진행하여 성능을 도출[1]
⎫	Sample 분화: Training Set 모델 만들 때 사용 / Validating Set 모델 조정하기 위해 사용 Test Set 모델의 최종 평가 위해 사용[2]
⎫	충분한 교차검증을 거치지 않을경우, 훈련 데이터에만 최적화 되는 과적합Overfitting이 일어남 . 오버피팅:  편향적으로 학습이 된 것.
